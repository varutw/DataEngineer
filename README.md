# Welcome!
My name is Varut Wiseschinda.
You can also call me Pete.
I'm from Thailand.
I'm a data engineer and data scientist.
Please find my Linkedin link [here](https://www.linkedin.com/in/varut-wiseschinda-807a24a1/).  

This repository shows my projects related to data engineering. The Technologies and tools in the data engineering world change very fast, so I have to keep track on it! I hope you like them. Nice to meet you!

![profile_picture](https://user-images.githubusercontent.com/45530179/218284170-bc7a5dc8-0e49-48a2-b9dc-780c90528f1d.jpg)


The main contents in this repository are as following:

![apache airflow](https://user-images.githubusercontent.com/45530179/218283892-470a8374-3f68-4e80-8670-0107222b1a3e.png)
![apache spark](https://user-images.githubusercontent.com/45530179/218284514-6ebd30fe-ed9d-4d0d-800b-a44ec87f7283.png)
![python](https://user-images.githubusercontent.com/45530179/218284733-47326023-7c10-4df6-adfd-bf178a03632b.jpg)
![google cloud](https://user-images.githubusercontent.com/45530179/218284646-4e675586-1d2a-4fab-a8ea-fdefff0d0581.png)

* __ETL_with_Airflow_in_Docker_Compose__ a folder containing the usage of Airflow with docker-compose

* __Data_Cleansing_with_Spark__ a notebook file that shows the processing of data cleansing with Pyspark

* __Data_Collection_with_Python__ a notebook file that shows the process of data collection, both from internal database and external data via API, with Python

* __Intermediate Python__ a folder containing intermediate-level Python codes

* __simple_pipeline_with_GCP__ creating a data pipeline in Google Cloud Platform (GCP) with Google Cloud Function.